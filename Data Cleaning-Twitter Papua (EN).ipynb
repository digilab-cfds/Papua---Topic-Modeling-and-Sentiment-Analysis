{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Twitter - Papua _EN_cleaning data(stemming and stopword removal terpisah).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8hM-_ZGe9Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaDPFyarfqK_",
        "colab_type": "code",
        "outputId": "83517b83-6db2-4492-d546-f7aba622d9a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "data_inter = pd.read_excel('Twitter EN Interactions.xlsx')\n",
        "data_post = pd.read_excel('Twitter EN Posts.xlsx')\n",
        "data_inter.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 129838 entries, 0 to 129837\n",
            "Data columns (total 14 columns):\n",
            "No                129838 non-null int64\n",
            "Date              129838 non-null object\n",
            "Author            129838 non-null object\n",
            "Post              129838 non-null object\n",
            "Original Reach    129838 non-null int64\n",
            "Viral Reach       129838 non-null int64\n",
            "Engagements       129838 non-null int64\n",
            "Viral Score       129821 non-null float64\n",
            "Sentiment         129838 non-null object\n",
            "Link              129838 non-null object\n",
            "Location          129838 non-null object\n",
            "Mood              0 non-null float64\n",
            "Sentence Type     0 non-null float64\n",
            "Tags              0 non-null float64\n",
            "dtypes: float64(4), int64(4), object(6)\n",
            "memory usage: 13.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bIf06ixftkg",
        "colab_type": "code",
        "outputId": "d4e29a4c-29f9-4679-ee17-9231daa13581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "data_post.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11477 entries, 0 to 11476\n",
            "Data columns (total 14 columns):\n",
            "No                11477 non-null int64\n",
            "Date              11477 non-null object\n",
            "Author            11477 non-null object\n",
            "Post              11477 non-null object\n",
            "Original Reach    11477 non-null int64\n",
            "Viral Reach       11477 non-null int64\n",
            "Engagements       11477 non-null int64\n",
            "Viral Score       11473 non-null float64\n",
            "Sentiment         11477 non-null object\n",
            "Link              11477 non-null object\n",
            "Location          11477 non-null object\n",
            "Mood              0 non-null float64\n",
            "Sentence Type     0 non-null float64\n",
            "Tags              0 non-null float64\n",
            "dtypes: float64(4), int64(4), object(6)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVcqZWvbf0Hn",
        "colab_type": "code",
        "outputId": "6ae00c01-2241-4017-dbbb-a052ab6d947c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "posts_inter = data_inter['Post']\n",
        "posts_post = data_post['Post']\n",
        "print('Data Twitter EN Interactions : ',len(posts_inter))\n",
        "print('Data Twitter EN Posts : ', len(posts_post))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Twitter EN Interactions :  129838\n",
            "Data Twitter EN Posts :  11477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VhVjTf2llY7",
        "colab_type": "text"
      },
      "source": [
        "## Cleaning without stemming and stopwords removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiG-C4urgBkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9_]+' #remove mention\n",
        "pat2 = r'https?://[A-Za-z0-9./]+' #remove link\n",
        "pat3 = r'RT' #remove RT\n",
        "pat4 = r'#[A-Za-z0-9_]+' #remove hashtag\n",
        "pat5 = r'pic.twitter.com/[A-Za-z0-9]+'\n",
        "combined_pat = r'|'.join((pat1,pat2,pat3,pat4,pat5))\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "def tweet_cleaner(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    souped = soup.get_text()\n",
        "    stripped = re.sub(combined_pat, '', souped) #delete pattern combined_pat in souped\n",
        "    try:\n",
        "        clean = stripped.decode(\"utf-8\").replace(u\"\\ufffd\", \"?\")\n",
        "    except:\n",
        "        clean = stripped\n",
        "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
        "    lower_case = letters_only.lower()\n",
        "    #words = tok.tokenize(lower_case)\n",
        "    #lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
        "    #filtered_words = [w for w in lemmatized if not w in stop_words] \n",
        "    #return (\" \".join(filtered_words)).strip()\n",
        "    return lower_case"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTC6SM5Jgq5C",
        "colab_type": "code",
        "outputId": "2d8f9b46-2c2e-4126-84a4-e83f28406308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "with tqdm(total=len(posts_inter)) as pbar:\n",
        "  clean_tweets_inter = []\n",
        "  for i in range(len(posts_inter)):\n",
        "    clean_tweets_inter.append(tweet_cleaner(posts_inter[i]))\n",
        "    time.sleep(0.1)\n",
        "    pbar.update(10)\n",
        "  \n",
        "clean_tweets_post = [tweet_cleaner(posts_post[i]) for i in range(len(posts_post))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "786100it [2:13:59, 97.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvdL_QRSj3ot",
        "colab_type": "code",
        "outputId": "b71f8ff4-414e-4287-fcc2-b9a05a5d05b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "clean_tweets_inter[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  yes sir but don t make fake news  be careful ',\n",
              " '   protesters burn local parliament building in west papua ',\n",
              " '   as vero notes below  this is the largest protest in jayapura in a long time  this might get serious              jayapura  west papua  ribuan massa teriakkan  papua merdeka  dalam aksi menentang rasisme   thousands of people shouting  free west papua  in the rally against racism  this is the biggest protest in years  ',\n",
              " '   this year      at least     people  mostly women and children  died  some at the hands of the security forces  many others died of hunger or sickness while fleeing their conflict ridden villages      today s minkes  racism at heart of jakarta papua conflict   ',\n",
              " '   indonesia s jokowi urges calm after violent west papua protests ',\n",
              " '   protesters burn local parliament building in west papua ',\n",
              " 'admin  rasa buzzer hoax    saya meminta klarifikasi dan permintaan maaf terbuka dari  atas pencemaran nama baik terhadap saya   ini negara hukum  saya selalu gunakan bahasa hukum sesuai kuhap  saya tidak pernah gunakan kata  penculikan   ',\n",
              " '   let s be clear  the papua protests were not sparked by  hoax  like indo govt claims  it was sparked by years of structural violence  even if reports of the racist attacks had been exaggerated  they were believed because they have happened  in one form or another  over and over ',\n",
              " 'keep fight    kalau saya memang berniat provokasi  saya bisa  dokumentasi yang saya terima jauh lebih banyak dari yang saya posting   tapi saya filter mana yang perlu diketahui demi kepentingan publik  sudah terlalu lama pemerintah menutup apa yang terjadi di papua ',\n",
              " '   let s be clear  the papua protests were not sparked by  hoax  like indo govt claims  it was sparked by years of structural violence  even if reports of the racist attacks had been exaggerated  they were believed because they have happened  in one form or another  over and over ',\n",
              " '   protesters burn local parliament building in west papua ',\n",
              " '   say no to racism    no matter what the color of our skin is or our culture is   still  our bone is white and blood is red  indonesia  you called them  monkey   same as you called it for yourself  cz we re brothers  papua is indonesia       ',\n",
              " '   say no to racism    no matter what the color of our skin is or our culture is   still  our bone is white and blood is red  indonesia  you called them  monkey   same as you called it for yourself  cz we re brothers  papua is indonesia       ',\n",
              " '   is   is this how white guilt feels  is this what my white classmates feel when i make passing remarks about colonialism        menurut kepala negara  alangkah lebih baiknya apabila masyarakat papua dan papua barat memaafkan jika merasa tersinggung  ',\n",
              " '   indonesian president calls for calm after violent protests in west papua ',\n",
              " '   say no to racism    no matter what the color of our skin is or our culture is   still  our bone is white and blood is red  indonesia  you called them  monkey   same as you called it for yourself  cz we re brothers  papua is indonesia       ',\n",
              " '   say no to racism    no matter what the color of our skin is or our culture is   still  our bone is white and blood is red  indonesia  you called them  monkey   same as you called it for yourself  cz we re brothers  papua is indonesia       ',\n",
              " '   say no to racism    no matter what the color of our skin is or our culture is   still  our bone is white and blood is red  indonesia  you called them  monkey   same as you called it for yourself  cz we re brothers  papua is indonesia       ',\n",
              " '   say no to racism    no matter what the color of our skin is or our culture is   still  our bone is white and blood is red  indonesia  you called them  monkey   same as you called it for yourself  cz we re brothers  papua is indonesia       ',\n",
              " '   let s be clear  the papua protests were not sparked by  hoax  like indo govt claims  it was sparked by years of structural violence  even if reports of the racist attacks had been exaggerated  they were believed because they have happened  in one form or another  over and over ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omtox2mgj7Fw",
        "colab_type": "code",
        "outputId": "327c9674-0097-454b-d75d-1666cc0c55ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "clean_tweets_post[:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' wp     wiranto discloses conspiracy involving separatist leader benny wenda   joe collins  ',\n",
              " 'unrest has been reported on the streets of manokwari after reports of racist abuse of papuan students          ',\n",
              " 'indonesian president calls for calm after violent protests in west papua ',\n",
              " 'indonesian president calls for calm after violent protests in west papua ',\n",
              " 'dani tribe chief eli mabel is pictured holding the remains of agat mamete mabel in the village of wogi in wamena in west papua  an island in the centre of papua new guinea   the indigenous tribe  who live in a    ',\n",
              " 'parliament set ablaze in indonesia unrest  ',\n",
              " 'protesters burn local parliament building in west papua ',\n",
              " 'the neighbourhood ',\n",
              " '  originally  papua doesn t belong to indonesia  our anchestor voiced our independence but still fought to claimed papua as our region   convenants  conferences  even armed combat  their efforts is not a thing to teach us for being a racist people ',\n",
              " 'thousands riot in papua  parliament building torched ',\n",
              " 'indonesian president joko widodo has sought to ease tensions after violent protests in several cities in west papua region following claims of racist abuse and physical mistreatment of papuan students  ',\n",
              " 'indonesian president calls for calm after violent protests in west papua  ',\n",
              " ' police search for inmates after  jail set ablaze ',\n",
              " 'west papua  large protests erupt after wave of arrests by indonesian military   unpo ',\n",
              " 'in west papua province s capital of manokwari  protesters burned the parliamentary building and local stores  a building previously occupied by west papua provincial governor dominggus mandacan was also burned and vehicles were torched  ',\n",
              " 'statement of aman the indigenous peoples alliance of the archipelago related to the siege and recent attacks against papua students in surabaya  via ',\n",
              " 'deploy full forces ',\n",
              " 'abc dodges surveillance to meet papuan activist fighting for independence  via ',\n",
              " 'west papua protesters set fire to parliament  protests against arrests of dozens of students turn violent  ',\n",
              " 'tensions are high in indonesia s papua and west papua provinces where protesters set fire to a local parliament building  and threw rocks at police  it was sparked by the arrest of more than    papuan students in surabaya ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFLUDh3yjPOU",
        "colab_type": "code",
        "outputId": "12790944-86fd-40b2-f605-3587fb1f64b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Jumlah Tweet EN Interaction : \",len(clean_tweets_inter))\n",
        "clean_tweets_remove_dups = list(dict.fromkeys(clean_tweets_inter))\n",
        "print(\"Jumlah Tweet EN Interaction tanpa duplikat : \", len(clean_tweets_remove_dups))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah Tweet ID Interaction :  129838\n",
            "Jumlah Tweet ID Interaction tanpa duplikat :  17707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVwaWnE4jhsm",
        "colab_type": "code",
        "outputId": "d9d33fbf-ec18-4cb9-8f52-d0812d44b7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Jumlah Tweet EN Post : \",len(clean_tweets_post))\n",
        "clean_tweets_remove_dups2 = list(dict.fromkeys(clean_tweets_post))\n",
        "print(\"Jumlah Tweet EN Post tanpa duplikat : \", len(clean_tweets_remove_dups2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah Tweet EN Post :  11477\n",
            "Jumlah Tweet EN Post tanpa duplikat :  8215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ5K3lrava5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "129838+11477"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khaN6Gtmu7UL",
        "colab_type": "text"
      },
      "source": [
        "## DATA TWEET BAHASA INGGRIS\n",
        "\n",
        "- Jumlah tweet EN interactions : 129.838\n",
        "- Jumlah tweet tanpa duplikat  : 17.707\n",
        "\n",
        "\n",
        "\n",
        "- Jumlah tweet EN posts       : 11.477\n",
        "- Jumlah tweet tanpa duplikat : 8215\n",
        "\n",
        "\n",
        "\n",
        "- Total tweet EN             : 141.315\n",
        "- Total tweet tanpa duplikat : 25.922"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn9x8e1eoFxf",
        "colab_type": "text"
      },
      "source": [
        "## Stemming and Stopwords Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNiamgGpoEQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "tok = WordPunctTokenizer()\n",
        "def tweet_cleaner2(text):\n",
        "  \n",
        "    words = tok.tokenize(text)\n",
        "    lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
        "    filtered_words = [w for w in lemmatized if not w in stop_words] \n",
        "    return (\" \".join(filtered_words)).strip()\n",
        " \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYiq09e9rjR0",
        "colab_type": "code",
        "outputId": "f9093367-1cdd-4745-9446-170ad7f5c540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "with tqdm(total=len(clean_tweets_inter)) as pbar:\n",
        "  clean_tweets_inter2 = []\n",
        "  for i in range(len(clean_tweets_inter)):\n",
        "    clean_tweets_inter2.append(tweet_cleaner2(clean_tweets_inter[i]))\n",
        "    pbar.update()\n",
        "  \n",
        "clean_tweets_post2 = [tweet_cleaner2(clean_tweets_post[i]) for i in range(len(clean_tweets_post))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 129838/129838 [00:18<00:00, 7198.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY9FEmBtsYqj",
        "colab_type": "code",
        "outputId": "2215acd7-6627-49a1-89b0-adaba144c2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with tqdm(total=len(clean_tweets_remove_dups)) as pbar:\n",
        "  clean_tweets_inter_remove_dups = []\n",
        "  for i in range(len(clean_tweets_remove_dups)):\n",
        "    clean_tweets_inter_remove_dups.append(tweet_cleaner2(clean_tweets_remove_dups[i]))\n",
        "    time.sleep(0.1)\n",
        "    pbar.update(10)\n",
        "  \n",
        "clean_tweets_post_remove_dups = [tweet_cleaner2(clean_tweets_remove_dups2[i]) for i in range(len(clean_tweets_remove_dups2))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "177070it [29:57, 98.52it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J1kbC6ljq6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_en_interactions = pd.DataFrame(clean_tweets_inter2)\n",
        "clean_en_posts = pd.DataFrame(clean_tweets_post2)\n",
        "\n",
        "clean_inter_remove_dups = pd.DataFrame(clean_tweets_inter_remove_dups)\n",
        "clean_post_remove_dups = pd.DataFrame(clean_tweets_post_remove_dups)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwfbAM98kZPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_en_interactions.to_csv('clean_EN_interactions.csv', index=False, header=['Post'])\n",
        "clean_en_posts.to_csv('clean_EN_posts.csv', index=False, header=['Post'])\n",
        "\n",
        "clean_inter_remove_dups.to_csv('clean_EN_interactions_remove_dups.csv', index=False, header=['Post'])\n",
        "clean_post_remove_dups.to_csv('clean_EN_posts_remove_dups.csv', index=False, header=['Post'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVypOPO1k1QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('clean_EN_interactions.csv')\n",
        "files.download('clean_EN_posts.csv')\n",
        "files.download('clean_EN_interactions_remove_dups.csv')\n",
        "files.download('clean_EN_posts_remove_dups.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}